import scrapy
import pandas as pd
from bs4 import BeautifulSoup
import requests
from selenium import webdriver

# 1.进入搜索结果
# 2.查找是否有该APP
# 3.如果有，则进入页面查看是否有”历史记录“
# 4.如果有历史记录，则进入历史记录页面，搜索对应的版本地址，
# 5.进入历史版本页面，抓取相应信息

class appDeail(scrapy.Spider):
    name = "m_app_detail"
    app_version_csv_pd = pd.read_csv('./app_version_0614.csv')
   
   
       
    def start_requests(self):
       
        for index,row in self.app_version_csv_pd.iterrows():
            
            print('现在开始处理：{name}:{version}'.format(name = row['app_name'],version = row['version']) )

            app_name = row['app_name']
            app_version = row['version']
            search_url = "https://m.wandoujia.com/search?key={name}&source=search".format(name = app_name)

            request = scrapy.Request(search_url,   callback = self.parse)
            
            request.cb_kwargs['app_name'] = app_name
            request.cb_kwargs['app_version'] = app_version
            
            yield request
            

            
    def parse(self,response, app_name,app_version):
        # 1、判断是有有app搜索结果
        app_search_result = response.xpath('//*[@id="j-search-list"]/li[*]/div[2]/h2/a[text()="{name}"]'.format(name = app_name))

        
        if app_search_result:
            print("搜索到APP：" + app_name)
            app_detail_url = app_search_result.attrib['href']
            # 进入APP详情
            request = response.follow(app_detail_url,   callback = self.parse_check_detail)
            request.cb_kwargs['app_name'] = app_name
            request.cb_kwargs['app_version'] = app_version
            
            yield request 
#             yield{
#             'app_name':app_name,
#             'app_version':app_version,
#             'app_store_url':app_detail_url
#         }


        else:
            print("未搜索到APP：" + app_name)
        

    def parse_check_detail(self,response, app_name,app_version):
        # 2. 检查是否有历史记录
        history_check = response.xpath('/html/body/div[2]/div[2]/div[2]/div[1]/div[2]/ul/li[*]/a[text() = "历史版本"]')


        if history_check:
            print("搜索到到历史记录：" + app_name)
            # 搜索历史记录详情页面
            history_version_url = response.url+"/history"
            request = response.follow(history_version_url,   callback = self.parse_check_version)
            request.cb_kwargs['app_name'] = app_name
            request.cb_kwargs['app_version'] = app_version
            
            yield request
            
        else:
            print("未搜索到到历史记录：" + app_name)
        
    def parse_check_version(self,response, app_name,app_version):
        # 3.检查是否有对应版本
        history_version = response.xpath('/html/body/div[2]/div[2]/div[1]/div[3]/div[1]/ul//a[1]/p[contains(text(),"{version}")]/..'.format( version=app_version))

        if history_version:
            print("搜索到到对应版本：" + app_name)
            history_version_app_url = history_version.attrib['href']
            
            request = response.follow(history_version_app_url,   callback = self.parse_version_detail)
            request.cb_kwargs['app_name'] = app_name
            request.cb_kwargs['app_version'] = app_version
            
            yield request
            
        else:
            print("未搜索到到对应版本：" + app_name)
            
        
    def parse_version_detail(self,response, app_name,app_version):


        # 名称
        # 版本
        # 商城地址
        # 图标地址
        icon_url = ''
        check_path = response.xpath("/html/body/div[2]/div[2]/div/div[1]/img")
                                     
        
        if check_path:
            icon_url = check_path.attrib["src"]
            

        # 大小
        size = ''
        check_path = response.xpath("/html/body/div[2]/div[3]/div[3]/div[1]/dl/dd[1]/meta")
                                     
        if check_path:
            size = float(check_path.attrib["content"].split("MB")[0])
        
        # 
        # 分类
        cate_str = ''
        cate_list = response.xpath("/html/body/div[2]/div[3]/div[3]/div[1]/dl/dd[2]")
                                    
        if cate_list:
            soup = BeautifulSoup( cate_list.get())

            for i in soup.find_all("a"):
                cate_str += (i.text)
                cate_str += ','

        # 安卓版本要求
        android_req_version = ''
        check_path = response.xpath("/html/body/div[2]/div[3]/div[3]/div[1]/dl/dd[3]/text()")
                                     
        if check_path: 
            android_req_version = check_path.get().split('\n')[0].split(' ')[1]


        # 权限
        permission_str = ''
        permission_list = response.xpath('//*[@id="j-perms-list"]')
        
        if permission_list:
            soup = BeautifulSoup(permission_list.get() )

            for i in soup.find_all("li"):
                permission_str+=(i.text)
                permission_str+=','

        # 隐私政策地址
        privacy = 0
        privacy_element = response.xpath('/html/body/div[2]/div[3]/div[3]/div[1]/dl/dd[3]/a')
                                          
        if privacy_element:
            privacy = privacy_element.attrib["href"]

        # 开发者
        developer = ''
        check_path = response.xpath('/html/body/div[2]/div[3]/div[3]/div[1]/dl/dd[4]/span/text()')
                                     
        if check_path:
            developer = check_path.get()
            


        yield{
            'app_name':app_name, # APP名称
            'app_version':app_version, # 版本
            'app_store_url':response.url, # 商城地址
            'icon_url':icon_url, # 图标地址
            'size':size, # 文件大小
            'cate_str':cate_str, # 类别
            'android_req_version':android_req_version, # Android版本要求
            'permission_str':permission_str, # 所需系统权限列表
            'privacy':privacy, #隐私URL地址
            'developer':developer # 开发者
        }
