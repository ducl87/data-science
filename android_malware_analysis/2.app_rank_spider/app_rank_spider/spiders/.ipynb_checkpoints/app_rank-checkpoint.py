import scrapy
import pandas as pd
from bs4 import BeautifulSoup
import requests
from selenium import webdriver

# 1.进入搜索结果
# 2.查找是否有该APP
# 3.如果有，则进入页面查看是否有”历史记录“
# 4.如果有历史记录，则进入历史记录页面，搜索对应的版本地址，
# 5.进入历史版本页面，抓取相应信息

class appRank(scrapy.Spider):
    
    name = "app_rank"
    app_rank_csv = pd.read_csv('./app_rank_list.csv')
   
   
       
    def start_requests(self):
       
        for index,row in self.app_rank_csv.iterrows():
            
            print('现在开始处理：{name}'.format(name = row['app_name'] ))
            app_name = row['app_name']
            app_url =  row['app_url']
            app_size =  row['size']

            request = scrapy.Request(app_url, callback = self.parse_app_detail)
            request.cb_kwargs['app_size'] = app_size
            
            yield request
            
        
    def parse_app_detail(self,response, app_size):


        # 名称
        app_name = ''
        check_path = response.xpath("/html/body/div[2]/div[2]/div[1]/div[2]/div[1]/p/span/text()")                       
        if check_path:
            app_name = check_path.get()
        
        # 版本
        app_version = ''
        check_path = response.xpath('/html/body/div[2]/div[2]/div[1]/div[2]/div[3]/a[2]')
        if check_path:
            app_version = check_path.attrib['data-app-vname']
        
        
        
        # 图标
        icon_url = ''
        check_path = response.xpath("/html/body/div[2]/div[2]/div[1]/div[1]/img")
                                     
        if check_path:
            icon_url = check_path.attrib["src"]
            

        
        # 
        # 分类
        cate_str = ''
        cate_list = response.xpath("/html/body/div[2]/div[2]/div[2]/div[2]/div[1]/dl/dd[1]")
                                    
        if cate_list:
            soup = BeautifulSoup( cate_list.get())

            for i in soup.find_all("a"):
                cate_str += (i.text)
                cate_str += ','

        # 安卓版本要求
        android_req_version = ''
        check_path = response.xpath('/html/body/div[2]/div[2]/div[2]/div[2]/div[1]/dl/dd[@itemprop="operatingSystems"]/text()')
                                     
                                     
                                     
        if check_path: 
            android_req_version = check_path.get().split('\n')[0].split(' ')[1]


        # 权限
        permission_str = ''
        permission_list = response.xpath('//*[@id="permission-modal"]/div[2]')
        
        if permission_list:
            soup = BeautifulSoup(permission_list.get() )
            
            for i in soup.find_all('p',attrs={'class': None}):
                permission_str+=(i.text)
                permission_str+=','

        # 隐私政策地址
        privacy = 0
        privacy_element = response.xpath('/html/body/div[2]/div[2]/div[1]/div[2]/div[2]/span[6]/a[1]')
                                          
        if privacy_element:
            privacy = privacy_element.attrib["href"]

        # 开发者
        developer = ''
        check_path = response.xpath('/html/body/div[2]/div[2]/div[1]/div[2]/div[2]/span[5]/text()')
                                     
        if check_path:
            developer = check_path.get().split('：')[1]
            


        yield{
            'app_name':app_name,
            'app_version':app_version,
            'app_store_url':response.url,
            'icon_url':icon_url,
            'size':app_size,
            'cate_str':cate_str,
            'android_req_version':android_req_version,
            'permission_str':permission_str,
            'privacy':privacy,
            'developer':developer
        }
